<!DOCTYPE html><html lang="en" ><head ><title >32 bit math?</title><meta name='viewport' content='width=device-width, initial-scale=0.66'><meta name='description' content='language:basic, target:desktop, category:game development'><link rel="styleSheet" href="../skins/granite/style.css" type="text/css"><style type="text/css">div.bbcode {padding: 8px;background: #E5E5E5;color: #000000;border: 1px dashed #B4B4BE;}</style></head><body ><table width=100% cellspacing=0 cellpadding=0><tr ><td class="menubarleft"></td><td class="menubar"><table cellspacing="0" cellpadding="0"><tr ><td >&nbsp;</td><td class="menuitemleft"></td><td class="menuitem"><a href="/" class="menuitem">News</a></td><td class="menuitemright"></td><td class="menuitemleft"></td><td class="menuitem"><a href="/forums.php" class="menuitem">Forums</a></td><td class="menuitemright"></td><td class="menuitemleft"></td><td class="menuitem"><a href="/codearcs.php" class="menuitem">Code</a></td><td class="menuitemright"></td><td class="menuitemleft"></td><td class="menuitem"><a href="/logs.php" class="menuitem">Logs</a></td><td class="menuitemright"></td><td class="menuitemleft"></td><td class="menuitem"><a href="/gallery.php" class="menuitem">Gallery</a></td><td class="menuitemright"></td><td class="menuitemleft"></td><td class="menuitem"><a href="/sdkspecs.php" class="menuitem">Specs</a></td><td class="menuitemright"></td><td class="menuitemleft"></td><td class="menuitem"><a href="/search.php" class="menuitem">Search</a></td><td class="menuitemright"></td></tr></table></td><td class="menubarright"></td></tr></table><div class="main"><h1 >32 bit math?</h1><a href="forums.php" >Community Forums</a>/<a href="topics.php?forum=530" >Monkey2 Talk</a>/<a href="#bottom" >32 bit math?</a><br><br>
<a name="2118171"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >marksibly</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#1">[#1]</a></td></tr></table></td></tr><tr ><td class="posttext"> Hi,<br><br>I'm just cleaning up the math stuff and wondering if there's any point adding 32 bit float versions of sin, cos, floor, etc, or should these all just use doubles?<br><br>In terms of passing/returning function params, floats/doubles will use the same FP registers (AFAIK) so I can't see there's any extra overhead there.<br><br>32 bit floats are IMO still a good idea for storage (vars, fields etc) as they're smaller (ie: less memory bandwidth) but when computing intermediate values is there any point anymore?<br><br>C++ still has float/double versions of sin, cos etc, but that could just be a legacy thing.<br><br>[edit]<br>Doubles significantly faster?<br>[/edit]<br><br><textarea class=codebox name="code" wrap=OFF readonly="true" rows="15" cols="80">
//Built with" g++ -std=c++11 -O3 test.cpp

#include &lt;stdio.h&gt;
#include &lt;chrono&gt;
#include &lt;cmath&gt;

double _tmp;

double testf(){

	std::chrono::time_point&lt;std::chrono::high_resolution_clock&gt; tm0,tm1;

	tm0=std::chrono::high_resolution_clock::now();

	float sum=0;
	for( int i=0;i&lt;10;++i ){
		for( float t=0;t&lt;360;t+=.0001 ){
			sum+=sinf( t );
//			sum+=floorf( t );
//			sum+=absf( t );
		}
	}

	tm1=std::chrono::high_resolution_clock::now();

	_tmp=sum;

	std::chrono::duration&lt;double&gt; elapsed=tm1-tm0;

	return elapsed.count();
}

template&lt;class T&gt; double test(){

	std::chrono::time_point&lt;std::chrono::high_resolution_clock&gt; tm0,tm1;

	tm0=std::chrono::high_resolution_clock::now();

	T sum=0;
	for( int i=0;i&lt;10;++i ){
		for( T t=0;t&lt;360;t+=.0001 ){
			sum+=std::sin( (T)t );
//			sum+=std::floor( (T)t );
//			sum+=std::abs( (T)t );
		}
	}

	tm1=std::chrono::high_resolution_clock::now();

	_tmp=sum;

	std::chrono::duration&lt;double&gt; elapsed=tm1-tm0;

	return elapsed.count();
}

int main(){

	for( int i=0;i&lt;10;++i ){

		double d=test&lt;float&gt;();

		printf( "float:%f\n",d );

		d=testf();

		printf( "floatf:%f\n",d );

		d=test&lt;double&gt;();

		printf( "double:%f\n",d );
	}
}
</textarea> <br><br></td></tr></table><br>
<a name="2118119"></a>

<a name="2118116"></a>

<a name="2118115"></a>

<a name="2118114"></a>

<a name="2118105"></a>

<a name="2118104"></a>

<a name="2118103"></a>

<a name="2118110"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >nullterm</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#2">[#2]</a></td></tr></table></td></tr><tr ><td class="posttext"> Think it's platform dependent, some may run faster with the 32bit version (what I'm used to using 99.99% of the time), others 64bit double might be faster.  <br><br>For 32bit, can you use the sinf/cosf function and test if there's any benefit?<br><br>Curious what the std::sin/cos do under the hood, if it uses the double value and convert, or if std::sin&lt;float&gt; uses the raw 32 bit one? <br><br></td></tr></table><br>
<a name="2118186"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >impixi</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#3">[#3]</a></td></tr></table></td></tr><tr ><td class="posttext"> Interesting. On my iMac (late 2015 edition, 6th Gen Intel i5 CPU - I think) I see over 3X difference. Also see over 3X difference on my notepad computer (Windows 10, 5th Gen Intel i7 CPU).<br><br>EDIT: Deleted my error... But never forgotten... <br><br></td></tr></table><br>
<a name="2118117"></a>

<a name="2118112"></a>

<a name="2118111"></a>

<a name="2118113"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >marksibly</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#4">[#4]</a></td></tr></table></td></tr><tr ><td class="posttext"> &gt; I see over 3X difference<br><br>In favour of double I assume?<br><br>I'm pretty surprised - even with 'sum' declared as a float, the double version is still faster. Seems like c++ is doing something weird here. <br><br></td></tr></table><br>
<a name="2118118"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >impixi</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#5">[#5]</a></td></tr></table></td></tr><tr ><td class="posttext"> Yes, in favour of double. <br><br></td></tr></table><br>
<a name="2118120"></a>

<a name="2118121"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >marksibly</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#6">[#6]</a></td></tr></table></td></tr><tr ><td class="posttext"> &gt; For 32bit, can you use the sinf/cosf function and test if there's any benefit?<br><br>Good point, but it doesn't make any noticeable difference - sinf and std::sin( float ) seem to do the same thing, which I'd always assumed (but never bothered checking!). Test code above updated. <br><br></td></tr></table><br>
<a name="2118122"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >FelipeA</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#7">[#7]</a></td></tr></table></td></tr><tr ><td class="posttext"> Tested it on raspberry pi 2 and double was 2x faster. So yeah! <br><br></td></tr></table><br>
<a name="2118125"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >marksibly</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#8">[#8]</a></td></tr></table></td></tr><tr ><td class="posttext"> &gt; Tested it on raspberry pi 2 and double was 2x faster<br><br>Wow! That would have been the target I'd be most concerned about! <br><br></td></tr></table><br>
<a name="2118127"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >GW_</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#9">[#9]</a></td></tr></table></td></tr><tr ><td class="posttext"> I'm not sure I understand all the ramifications of eliminating the 32bit float versions.  I do a lot of statistical stuff and machine learning with Bmax and frequently need to connect with other code in c or dll's.  <br>I'd like to port some of my stuff over when the language stabilizes. Will your proposal effect that?  Is Monkey2 designed build both 32 and 64bit apps? <br><br></td></tr></table><br>
<a name="2118164"></a>

<a name="2118165"></a>

<a name="2118166"></a>

<a name="2118167"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >marksibly</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#10">[#10]</a></td></tr></table></td></tr><tr ><td class="posttext"> There shouldn't be any ramifications beyond float math functions being faster and, I guess, more accurate!<br><br>In fact, I just tested 32/64 bit versions on Windows and 32 bit builds are 3X faster while 64 bit are 5X! Built with:<br><br>g++ -std=c++11 -O3 -m32 t.cpp<br>g++ -std=c++11 -O3 -m64 t.cpp<br><br>A bit worried I'm 'missing something' here though...<br><br>&gt; BTW: &lt;chrono&gt; is not implemented under Windows, IIRC.<br><br>Seems to work if you use -std=c++11. <br><br></td></tr></table><br>
<a name="2118170"></a>

<a name="2118172"></a>

<a name="2118173"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >marksibly</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#11">[#11]</a></td></tr></table></td></tr><tr ><td class="posttext"> Ok, my bad, the compiler was removing the 'sin' calls since sum is never used!<br><br>Fixed now and the results are closer to what I'd expect - on windows, doubles are still a little bit faster, while on macos they're are teeny bit slower.<br><br>But in neither case are the calls to sin inlined, so it's probably possible to make them even faster with the right compiler options...<br><br>Can you test on raspberry pi again, ilovepixel?<br><br>Also updated test code above. <br><br></td></tr></table><br>
<a name="2118174"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >FelipeA</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#12">[#12]</a></td></tr></table></td></tr><tr ><td class="posttext"> Hi Mark,<br>In the templated test, did you mean to cast to T or to double? Because if you run the test&lt;float&gt;() it won't run sin/cos/abs for double but for float. <br><br></td></tr></table><br>
<a name="2118175"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >marksibly</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#13">[#13]</a></td></tr></table></td></tr><tr ><td class="posttext"> Cast. This tests the std::sin overloads for both float and double. <br><br></td></tr></table><br>
<a name="2118182"></a>

<a name="2118183"></a>

<a name="2118185"></a>

<a name="2118187"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >impixi</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#14">[#14]</a></td></tr></table></td></tr><tr ><td class="posttext"> &gt;&gt; BTW: &lt;chrono&gt; is not implemented under Windows, IIRC.<br>&gt; Seems to work if you use -std=c++11.<br><br>OMG. I can't believe I forgot to use that switch.<br><br><div class="quote"> <br>Fixed now and the results are closer to what I'd expect - on windows, doubles are still a little bit faster, while on macos they're are teeny bit slower.<br> <br></div><br><br>I see those results here too... <br><br></td></tr></table><br>
<a name="2118197"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >FelipeA</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#15">[#15]</a></td></tr></table></td></tr><tr ><td class="posttext"> <div class="quote"> Cast. This tests the std::sin overloads for both float and double. <br></div><br><br>I was asking because the cast seem redundant. <br><br>This is the overall result on raspberry pi 2<br><pre class=code>
float:41.645984
floatf:41.605996
double:15.027483
</pre><br><br>It's pretty good!<br><br>Edit:<br><br>It looks like if I printf the _tmp value at the end I get almost a similar performance between double and float. I think maybe the compiler is optimizing the variable. A thing a noticed while analyzing the assembly is that for some reason is converting from float to double when doing the 32 bit operation.<br><br>test&lt;float&gt;<br><pre class=code>
		for (T t = 0; t&lt;360; t += .0001)
00007FF6CF8011CB  cvtps2pd    xmm1,xmm6  
		{
			sum += std::sin((T)t);
00007FF6CF8011CE  addss       xmm7,xmm0  
00007FF6CF8011D2  addsd       xmm1,xmm8  
00007FF6CF8011D7  cvtpd2ps    xmm6,xmm1  
00007FF6CF8011DB  comiss      xmm9,xmm6  
00007FF6CF8011DF  ja          test&lt;float&gt;+0C3h (07FF6CF8011C3h)  
</pre><br><br>as you see if it didn't use the instruction "cvtps2pd" and "cvtpd2ps" in the float test it would be almost the same.with the double one. This instructions make you lose about 8 cycles. Is not much but when doing a lot of iteration it can be noticeable.<br><br>test&lt;double&gt;<br><pre class=code>
			sum += std::sin((T)t);
00007FF659B51373  movaps      xmm0,xmm6  
00007FF659B51376  call        sin (07FF659B52444h)  
00007FF659B5137B  addsd       xmm6,xmm8  
00007FF659B51380  addsd       xmm7,xmm0  
00007FF659B51384  comisd      xmm9,xmm6  
00007FF659B51389  ja          test&lt;double&gt;+0C3h (07FF659B51373h)  
</pre><br><br>I also thing the code benefits from auto vectorization. Which usually is a compiler dependency. For example when I tried the same code with mingw64-gcc it gave almost the same performance between floats and doubles. Also if at some point you add a branch in the middle you may also mess up auto vectorization.<br><br>I haven't looked in detail at the output of raspberry pi yet. I'll look it during the weekend. <br><br></td></tr></table><br>
<a name="2118191"></a>

<a name="2118208"></a>

<a name="2118209"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >marksibly</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#16">[#16]</a></td></tr></table></td></tr><tr ><td class="posttext"> &gt; It looks like if I printf the _tmp value at the end I get almost a similar performance between double and float. I think maybe the compiler is optimizing the variable.<br><br>Yep, looks like it. The pi compiler (linux g++?) apparently does a better job than mingw or llvm!<br><br>&gt; A thing a noticed while analyzing the assembly is that for some reason is converting from float to double when doing the 32 bit operation.<br><br>Yeah, I noticed this too. It seems unnecessary but I assume they know what they're doing...?<br><br>Another thing I noticed is that the compiler never inlined 'sin' - it was always a function call (missing from your first loop due to _tmp being optimized out?). I assume the FPU has sin though and it could just be a case of finding the right compiler switches. I tried a few but didn't get far.<br><br>In fact, if the compiler is generating a function call then that would explain the double/float conversion as the parameter needs to be in the correct format.<br><br>But I'm not even sure what FPU's are common these days! mmx? sse? Which is better etc? Anyone know more about this? <br><br></td></tr></table><br>
<a name="2118221"></a>

<a name="2118222"></a>

<a name="2118223"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >FelipeA</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#17">[#17]</a></td></tr></table></td></tr><tr ><td class="posttext"> At least msvc is using the avx (xmm0 - xmm7 and xmm8 - xmm15 in 64bit arch) vector register for doing floating point math. mingw-gcc is not. The funny thing is that while debugging I noticed that it's not really vectorizing the code but just using a 128bit register to do operations over a single 32/64 bit value, which for me seems like a total waste. I am pretty sure the code could go upto 2x faster if properly vectorized. But of course it's a very specific case so It wouldn't work as a "compiler optimization". <br><br></td></tr></table><br>
<a name="2118248"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td class="posthead"><table width=100% cellspacing=0 cellpadding=0><tr ><td >dawlane</td><td align="right"><font class=tiny>(Posted 2016)</font>&nbsp;<a href="#18">[#18]</a></td></tr></table></td></tr><tr ><td class="posttext"> The output I'm getting on an 1st Gen i7 with Ubuntu 4.9.3-8ubuntu2~14.04 is<br>32bit <br>float:0.575295                                                                                                              <br>floatf:0.531015                                                                                                             <br>double:1.626234                                                                                                             <br><br>64bit<br>float:0.514282<br>floatf:0.513274<br>double:1.375198<br><br>You can find out the defaults that GCC uses with<br>g++ -Q --help=target.<br>g++ -Q --help=optimizers<br><br>You would need to see <a href="https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html" target="_blank">https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html</a> for what is invoked with the -O3 switch.<br><br>&gt;But I'm not even sure what FPU's are common these days! mmx? sse? Which is better etc? Anyone know more about this?<br>I would think that it would be more of 'what instructions a CPU supports than what is common'. I would think that Core2 sse instruction set would be the most common for a few more years. <br><br></td></tr></table><br>
<a name="bottom"></a>
<table width=100% cellspacing=0 cellpadding=0><tr ><td align="right"><a href="http://monkeycoder.co.nz" target="_blank"><img src="/img/monkey2.svg" ></a> <a href="https://github.com/blitz-research" target="_blank"><img src="/img/github.svg" ></a> <a href="https://discord.gg/qJccbSp" target="_blank"><img src="/img/discord.svg" ></a></td></tr></table><br></div><br><table width="100%"><tr><td></body></html lang="en">
